package com.magma.compiler;

import com.magma.compiler.lexer.MagmaLexer;
import com.magma.compiler.lexer.Token;

import java.util.List;

/**
 * Simple debug utility to print tokens generated by the lexer.
 */
public class LexerDebugSimple {
    public static void main(String[] args) {
        // Test case 1: Single character tokens
        String source1 = "(){},.-+;*";
        System.out.println("Source 1: " + source1);
        MagmaLexer lexer1 = new MagmaLexer(source1);
        List<Token> tokens1 = lexer1.tokenize();
        System.out.println("Token count: " + tokens1.size());
        for (int i = 0; i < tokens1.size(); i++) {
            System.out.println(i + ": " + tokens1.get(i).getType() + " - " + tokens1.get(i).getLexeme());
        }
        System.out.println();
        
        // Test case 2: Integer literals
        String source2 = "0 42 -1 +10";
        System.out.println("Source 2: " + source2);
        MagmaLexer lexer2 = new MagmaLexer(source2);
        List<Token> tokens2 = lexer2.tokenize();
        System.out.println("Token count: " + tokens2.size());
        for (int i = 0; i < tokens2.size(); i++) {
            System.out.println(i + ": " + tokens2.get(i).getType() + " - " + tokens2.get(i).getLexeme());
        }
        System.out.println();
        
        // Test case 3: Identifiers and keywords
        String source3 = "var name = \"John\"; if true { print name; }";
        System.out.println("Source 3: " + source3);
        MagmaLexer lexer3 = new MagmaLexer(source3);
        List<Token> tokens3 = lexer3.tokenize();
        System.out.println("Token count: " + tokens3.size());
        for (int i = 0; i < tokens3.size(); i++) {
            System.out.println(i + ": " + tokens3.get(i).getType() + " - " + tokens3.get(i).getLexeme());
        }
    }
}